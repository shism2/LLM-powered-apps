{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load environment variables\n",
    "#### Case 1) If you use OpenAI's ChatGPT, then you need store the following variables in '.env' file:\n",
    "\n",
    "- 'OPENAI_API_KEY' = XXXXXXXXXXXXXXX\n",
    "- 'model_name' = XXXXXXXXXXXXXXX\n",
    "\n",
    "##### Case 2) If you use AzureOpenAI's ChatGPT, then you need store the following variables in '.env' file:\n",
    "\n",
    "- 'OPENAI_API_TYPE' = XXXXXXXXXXXXXXX\n",
    "- 'OPENAI_API_VERSION' = XXXXXXXXXXXXXXX\n",
    "- 'OPENAI_API_BASE' = XXXXXXXXXXXXXXX\n",
    "- 'OPENAI_API_KEY' = XXXXXXXXXXXXXXX\n",
    "- 'deployment_name' = XXXXXXXXXXXXXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys  \n",
    "from dotenv import load_dotenv\n",
    "sys.path.extend([\"..\", '../..'])  \n",
    "_ = load_dotenv('.env')\n",
    "\n",
    "\n",
    "model_name = os.getenv('deployment_name') if os.getenv('OPENAI_API_TYPE') == 'azure' else os.getenv('model_name')\n",
    "if os.getenv('OPENAI_API_TYPE') == 'azure':\n",
    "    deployment_name = model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get an example of input variables for the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  The oldest member of BTS is Jin, and his birth month is December. He was born on December 4, 1992.\n",
      "2.  The current President of South Korea, Yoon Suk Yeol, was born on 18 December 1960. So, his birth month is December.\n"
     ]
    }
   ],
   "source": [
    "from utils.pydantic_models.agent_trajectory import Trajectory\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "trajectory_getting_func = convert_pydantic_to_openai_function(Trajectory)\n",
    "\n",
    "\n",
    "task = \"Which is bigger? BTS's oldest member's birth month vs. incumbent Korean president's birth month\"\n",
    "scratchpad = \"\"\"Entering new AgentExecutor chain...\n",
    "Thought: I need to find out the birth month of the oldest member of BTS and the birth month of the current Korean president. \n",
    "\n",
    "Action:\n",
    "{\n",
    "  \"action\": \"GetFromYDC\",\n",
    "  \"action_input\": {\n",
    "    \"Query\": \"Oldest member of BTS birth month\"\n",
    "  }\n",
    "}\n",
    "\n",
    "The oldest member of BTS is Jin, and his birth month is December. He was born on December 4, 1992.Action:\n",
    "\n",
    "Action:\n",
    "\n",
    "{\n",
    "  \"action\": \"GetFromYDC\",\n",
    "  \"action_input\": {\n",
    "    \"Query\": \"Current Korean president birth month\"\n",
    "  }\n",
    "}\n",
    "\n",
    "The current President of South Korea, Yoon Suk Yeol, was born on 18 December 1960. So, his birth month is December.\n",
    "\n",
    "Action:\n",
    "{\n",
    "  \"action\": \"Final Answer\",\n",
    "  \"action_input\": \"The birth month of the oldest member of BTS, Jin, and the birth month of the current Korean president, Yoon Suk Yeol, are both December. Therefore, neither is bigger as they are the same.\"\n",
    "}\n",
    "\n",
    "\n",
    "Finished chain.\"\"\"\n",
    "\n",
    "from typing import Literal\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI, AzureChatOpenAI\n",
    "from utils.custom_output_parsers.functioncall_output_parsers import ReActOutputJsonKeyStrParser\n",
    "\n",
    "\n",
    "def get_OpenAI_chain_1(provider: Literal['ChatOpenAI', 'AzureChatOpenAI'], model_or_deployment_name: str):\n",
    "    if provider == 'ChatOpenAI':\n",
    "        chat_model = ChatOpenAI(model_name=model_or_deployment_name, temperature=0).bind(functions=[trajectory_getting_func], function_call={'name':'Trajectory'})\n",
    "    else:\n",
    "        chat_model = AzureChatOpenAI(deployment_name=model_or_deployment_name, temperature=0).bind(functions=[trajectory_getting_func], function_call={'name':'Trajectory'})\n",
    "    return chat_model\n",
    "\n",
    "prompt_1 = hub.pull(\"jet-taekyo-lee/tagging-extracting-agent-scratchpad\")\n",
    "provider = 'AzureChatOpenAI'\n",
    "model_or_deployment_name = os.getenv('model_name') if provider == 'ChatOpenAI' else os.getenv('deployment_name')\n",
    "chat_model_1 = get_OpenAI_chain_1(provider, model_or_deployment_name)\n",
    "parser = ReActOutputJsonKeyStrParser(key='observations')\n",
    "\n",
    "chain_1 = prompt_1 | chat_model_1 | parser\n",
    "observations = chain_1.invoke({'task':task, 'scratchpad':scratchpad})\n",
    "print(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fetch the prompt and create a chain (using LCEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_OpenAI_chain_2(provider: Literal['ChatOpenAI', 'AzureChatOpenAI'], model_or_deployment_name: str):\n",
    "    if provider == 'ChatOpenAI':\n",
    "        chat_model = ChatOpenAI(model_name=model_or_deployment_name, temperature=0)\n",
    "    else:\n",
    "        chat_model = AzureChatOpenAI(deployment_name=model_or_deployment_name, temperature=0)\n",
    "    return chat_model\n",
    "\n",
    "\n",
    "prompt_2 = hub.pull(\"jet-taekyo-lee/response-based-on-observation\")\n",
    "chat_model_2 = get_OpenAI_chain_2(provider, model_or_deployment_name)\n",
    "chain_2 = prompt_2 | chat_model_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both are the same.\n"
     ]
    }
   ],
   "source": [
    "response = chain_2.invoke({'task':task, 'observations':observations})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('llm_agents')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3fb45ff54312d810d3b33eec9af47862c42661f076ce6b0d7045a13e18ceae3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
