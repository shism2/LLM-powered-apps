{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load environment variables\n",
    "#### Case 1) If you use OpenAI's ChatGPT, then you need store the following variables in '.env' file:\n",
    "\n",
    "- 'OPENAI_API_KEY' = XXXXXXXXXXXXXXX\n",
    "- 'model_name' = XXXXXXXXXXXXXXX\n",
    "\n",
    "##### Case 2) If you use AzureOpenAI's ChatGPT, then you need store the following variables in '.env' file:\n",
    "\n",
    "- 'OPENAI_API_TYPE' = 'azure'\n",
    "- 'OPENAI_API_VERSION' = '2023-08-01-preview'\n",
    "- 'OPENAI_API_BASE' = XXXXXXXXXXXXXXX\n",
    "- 'OPENAI_API_KEY' = XXXXXXXXXXXXXXX\n",
    "- 'deployment_name' = XXXXXXXXXXXXXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys  \n",
    "from dotenv import load_dotenv\n",
    "sys.path.extend([\"..\", '../..'])  \n",
    "_ = load_dotenv('.env')\n",
    "\n",
    "\n",
    "model_name = os.getenv('deployment_name') if os.getenv('OPENAI_API_TYPE') == 'azure' else os.getenv('model_name')\n",
    "if os.getenv('OPENAI_API_TYPE') == 'azure':\n",
    "    deployment_name = model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get a random persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"gender\": \"male\", \"name\": \"William Short\", \"language\": \"English\", \"nationality\": \"Netherlands\", \"age\": 89, \"hobbies\": [\"hiking\", \"painting\", \"gardening\", \"pottery\"], \"talkative\": false, \"characteristics\": [\"unknown\", \"NotJovial\", \"Vibrant\"], \"education_level\": \"undergraduate_college_level\"}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.pydantic_models.user_persona import UserPersona, get_random_user_persona\n",
    "persona = get_random_user_persona().json()\n",
    "persona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get OpenAI functions\n",
    "This prompt is supposed to work with OpenAI Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pydantic_models.user_persona import UserProfile\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "openai_function_profile = convert_pydantic_to_openai_function(UserProfile)\n",
    "\n",
    "### You can also get openai_function_profile in this way\n",
    "# with open('openai_function_profile.json', 'r') as f:  \n",
    "#     openai_function_profile = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fetch the prompt and create a chain (using LCEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI, AzureChatOpenAI\n",
    "\n",
    "def get_OpenAI_chain(provider: Literal['ChatOpenAI', 'AzureChatOpenAI'], model_or_deployment_name: str):\n",
    "    if provider == 'ChatOpenAI':\n",
    "        chat_model = ChatOpenAI(model_name=model_or_deployment_name, temperature=0).bind(functions=[openai_function_profile], function_call={'name':'UserProfile'})\n",
    "    else:\n",
    "        chat_model = AzureChatOpenAI(deployment_name=model_or_deployment_name, temperature=0).bind(functions=[openai_function_profile], function_call={'name':'UserProfile'})\n",
    "    return chat_model\n",
    "\n",
    "prompt = hub.pull(\"jet-taekyo-lee/persona-description\")\n",
    "provider = 'AzureChatOpenAI'\n",
    "model_or_deployment_name = os.getenv('model_name') if provider == 'ChatOpenAI' else os.getenv('deployment_name')\n",
    "chat_model = get_OpenAI_chain(provider, model_or_deployment_name)\n",
    "\n",
    "chain = prompt | chat_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Get a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"original_persona\": {\n",
      "    \"gender\": \"male\",\n",
      "    \"name\": \"William Short\",\n",
      "    \"language\": \"English\",\n",
      "    \"nationality\": \"Netherlands\",\n",
      "    \"age\": 89,\n",
      "    \"hobbies\": [\"hiking\", \"painting\", \"gardening\", \"pottery\"],\n",
      "    \"talkative\": false,\n",
      "    \"characteristics\": [\"unknown\", \"NotJovial\", \"Vibrant\"],\n",
      "    \"education_level\": \"undergraduate_college_level\"\n",
      "  },\n",
      "  \"refined_persona\": {\n",
      "    \"gender\": \"male\",\n",
      "    \"name\": \"William Short\",\n",
      "    \"language\": \"English\",\n",
      "    \"nationality\": \"Netherlands\",\n",
      "    \"age\": 89,\n",
      "    \"hobbies\": [\"hiking\", \"painting\", \"gardening\", \"pottery\"],\n",
      "    \"talkative\": false,\n",
      "    \"characteristics\": [\"NotJovial\", \"Vibrant\"],\n",
      "    \"education_level\": \"undergraduate_college_level\"\n",
      "  },\n",
      "  \"refined_persona_description\": {\n",
      "    \"description_of_persona\": \"William Short is an 89-year-old male from the Netherlands. He is a college graduate and is fluent in English. Despite his age, he is quite active and enjoys hobbies such as hiking, painting, gardening, and pottery. He is not very talkative and tends to keep to himself. His personality is vibrant, but he is not particularly jovial. His persona does not reveal any other specific characteristics.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'persona':persona})\n",
    "print(response.additional_kwargs['function_call']['arguments'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('llm_agents')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3fb45ff54312d810d3b33eec9af47862c42661f076ce6b0d7045a13e18ceae3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
