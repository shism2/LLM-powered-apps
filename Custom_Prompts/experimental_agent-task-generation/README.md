# Background
This custom prompt is engineered to generate tasks for agentic applications, empowering an LLM to orchestrate plans and make subsequent decisions. It utilizes three input variables: {tool_descriptions}, {num_tasks}, and {h}:

 - tool_descriotions : Provides details of the tools available to the agent, including the name, usage, and arguments for each. The simplest method to obtain this information is to utilize the 'utils.agent_tools.render.tools_render.render_text_description_and_args' function from LangChain.
```
tool_descriotions = 'tool_1: Googling_from_SerpAPI: This is useful for when you need to search Google to answer questions. You should ask targeted questions. Input should be a single string not a list. Never pass in ['string', $query], Just pass in $query., args: {'tool_input': {'type': 'string'}}\ntool_2: GetFromOpenWeatherMap: Return the weather information based on current location. Not only can you get the current weather, you can also get weather prediction up to 7 days in advance. This function is two-input function. Input 1: 'IANA_timezone' is the timezone name of the current location with respect to IANA Time Zone Databasse. The default value is 'Asia/Seoul' (str). Input 2: 'Days_from_now', is the number of days from today. The default value is 0 (int). value is string. Only use this function for the current weather and weather forecast for up to 7 days. This functon CANNOT provide historical weather data., args: {'IANA_timezone': {'title': 'Iana Timezone', 'description': 'the region you want to know the weather for', 'default': 'Asia/Seoul', 'type': 'string'}, 'Days_from_now': {'title': 'Days From Now', 'description': 'Number of days after today. 0 means today and 1 means tomorrow, and 2 means the day after tomorrow', 'default': 0, 'minimum': 0, 'maximum': 7, 'type': 'integer'}}\ntool_3: GetFromDatetimeModule: Return the current time based on location. The input, whose type is string, is the timezone name of the current location with respect to IANA Time Zone Databasse. The default value is Asia/Seoul. The return value is also string. Only use this function for the current time., args: {'IANA_timezone': {'title': 'Iana Timezone', 'description': 'the region you want to know the current time in', 'default': 'Asia/Seoul', 'type': 'string'}}\ntool_4: Python_REPL: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`., args: {'query': {'title': 'Query', 'type': 'string'}}'
```

 - num_tasks : Specifies the number of tasks to be generated by the output.
```
num_tasks = 3
```

 - h : Represents the horizon parameter, limiting the number of actions an agent can execute. The maximum number of tool uses to complete a task is determined by Max=h*N, where N is the total number of available tools.
```
h = 2
```

The prompt is designed to produce a batch of tasks suitable for these parameters.

# Use Cases
This prompt excels in creating datasets of tasks tailored for agentic applications. The tasks generated exhibit the following characteristics:
- Tool Comprehension: Tasks demand an understanding of each tool's function. The total tool count is referred to as 'N'.
- LLM Integration: Tasks may tap into the LLM's inherent capabilities for partial solutions, but will require external tools to fully resolve.
- Tool Utilization: Multiple uses of the same tool may be necessary for partial or complete task resolution.
- Solution Horizon: The task's complexity is regulated by the 'horizon' parameter {h}, ensuring the number of tool uses does not surpass {h}*N.
- Task Clarity: Clear, concise task descriptions are paramount, avoiding direct references to tool specifics or instructions on tool selection.

# How to play around?
The following code snippet provides an example of how you can utilize the prompt with LLMs. 
```
from langchain import hub
from langchain.chat_models import AzureChatOpenAI, ChatOpenAI

prompt = hub.pull("jet-taekyo-lee/agent-task-generation")
deployment_name = os.getenv('deployment_name')


chat_model = AzureChatOpenAI(deployment_name=deployment_name, temperature=0) if os.getenv('OPENAI_API_TYPE') == 'azure' else ChatOpenAI(model_name=model_name, temperature=0)
task_generation_chain = prompt | chat_model

answer = task_generation_chain.invoke({'tool_descriotions':tool_descriotions, 'num_tasks':3, 'h':2})
print(answer.content)
```

Visit the provided [GitHub repo](https://github.com/Taekyo-Lee/LLM-powered-apps/tree/main/Custom_Prompts/persona-based-dialog) and download [persona-based-dialog/nb_persona-based-dialog.ipynb](https://github.com/Taekyo-Lee/LLM-powered-apps/blob/main/Custom_Prompts/persona-based-dialog/nb_persona-based-dialog.ipynb) file.