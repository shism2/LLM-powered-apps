{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load environment variables\n",
    "#### Case 1) If you use OpenAI's ChatGPT, then you need store the following variables in '.env' file:\n",
    "\n",
    "- 'OPENAI_API_KEY' = XXXXXXXXXXXXXXX\n",
    "- 'model_name' = XXXXXXXXXXXXXXX\n",
    "\n",
    "##### Case 2) If you use AzureOpenAI's ChatGPT, then you need store the following variables in '.env' file:\n",
    "\n",
    "- 'OPENAI_API_TYPE' = XXXXXXXXXXXXXXX\n",
    "- 'OPENAI_API_VERSION' = XXXXXXXXXXXXXXX\n",
    "- 'OPENAI_API_BASE' = XXXXXXXXXXXXXXX\n",
    "- 'OPENAI_API_KEY' = XXXXXXXXXXXXXXX\n",
    "- 'deployment_name' = XXXXXXXXXXXXXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys  \n",
    "from dotenv import load_dotenv\n",
    "sys.path.extend([\"..\", '../..'])  \n",
    "_ = load_dotenv('.env')\n",
    "\n",
    "\n",
    "model_name = os.getenv('deployment_name') if os.getenv('OPENAI_API_TYPE') == 'azure' else os.getenv('model_name')\n",
    "if os.getenv('OPENAI_API_TYPE') == 'azure':\n",
    "    deployment_name = model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a scratchpad-compressing chain (using LCEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "agent_scratchpad_compression_prompt = hub.pull(\"jet-taekyo-lee/agent-scratchpad-compression\")\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI, ChatOpenAI\n",
    "llm = AzureChatOpenAI(deployment_name=deployment_name, temperature=0) if os.getenv('OPENAI_API_TYPE') == 'azure' else ChatOpenAI(model_name=model_name, temperature=0)\n",
    "\n",
    "agent_scratchpad_compression_chain = agent_scratchpad_compression_prompt | llm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fetch the prompt and create a chain (using LCEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"jet-taekyo-lee/rag-style-react\")\n",
    "\n",
    "from utils.agent_components.configurations import Configurations\n",
    "from utils.agent_tools.tools.web_search_tools import get_web_search_tools\n",
    "from utils.agent_tools.tools.weather_tools import GetFromOpenWeatherMap\n",
    "from utils.agent_tools.tools.time_tools import GetFromDatetimeModule\n",
    "from utils.agent_tools.tools.python_repl_tools import GetLangChainPythonRepl\n",
    "from langchain.tools.render import render_text_description_and_args\n",
    "config = Configurations(provider='AzureChatOpenAI')\n",
    "search_tool = get_web_search_tools(config)\n",
    "weather_tool = GetFromOpenWeatherMap()\n",
    "time_tool = GetFromDatetimeModule()\n",
    "python_repl_tool = GetLangChainPythonRepl()\n",
    "tools = [search_tool, weather_tool, time_tool, python_repl_tool]\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = prompt.partial(\n",
    "        tools=render_text_description_and_args(tools),\n",
    "        tool_names=\", \".join([t.name for t in tools]),\n",
    ")\n",
    "\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI, ChatOpenAI\n",
    "llm = AzureChatOpenAI(deployment_name=deployment_name, temperature=0) if os.getenv('OPENAI_API_TYPE') == 'azure' else ChatOpenAI(model_name=model_name, temperature=0)\n",
    "\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from utils.custom_output_parsers.agent_intermediatte_steps import format_intersteps_to_compressed_scratchpad\n",
    "from langchain.agents.output_parsers import JSONAgentOutputParser\n",
    "\n",
    "rag_style_react_agent = ( RunnablePassthrough.assign( compressed_agent_scratchpad = lambda x : format_intersteps_to_compressed_scratchpad(x[\"intermediate_steps\"], agent_scratchpad_compression_chain) )\n",
    "    | prompt | llm | JSONAgentOutputParser()\n",
    ")\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "rag_style_react_agent_executor = AgentExecutor(agent=rag_style_react_agent, tools=tools, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The user wants to know the current weather in New York. I don't need to know the current time for this task, I can directly use the GetFromOpenWeatherMap tool to get the current weather in New York.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "\"action\": \"GetFromOpenWeatherMap\",\n",
      "\"action_input\": {\"IANA_timezone\": \"America/New_York\", \"Days_from_now\": 0}\n",
      "}\n",
      "```\u001b[0m\u001b[33;1m\u001b[1;3mtimezone: New York County, current time(year-month-day): 2023-11-12-17-48, temperature: 5.340000000000032, humidity: 45, wind_speed: 4.36, weather_summary: Expect a day of partly cloudy with clear spells.\u001b[0m\u001b[32;1m\u001b[1;3mThought: The user is asking for the current weather in New York. However, the additional information provided already gives the current weather in New York on November 12th, 2023. Therefore, I don't need to use any tools to find the weather. I can directly provide the answer.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "\"action\": \"Final Answer\",\n",
      "\"action_input\": \"The current weather in New York on November 12th, 2023, is partly cloudy with clear spells, a temperature of 5.34°C, humidity at 45%, and a wind speed of 4.36 m/s.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the weather in new york?',\n",
       " 'output': 'The current weather in New York on November 12th, 2023, is partly cloudy with clear spells, a temperature of 5.34°C, humidity at 45%, and a wind speed of 4.36 m/s.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_style_react_agent_executor.invoke({'input':'What is the weather in new york?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('llm_agents')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3fb45ff54312d810d3b33eec9af47862c42661f076ce6b0d7045a13e18ceae3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
