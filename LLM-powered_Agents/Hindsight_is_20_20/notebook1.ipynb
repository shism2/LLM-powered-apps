{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a helpful assistant. Respond to the human as helpfully and accurately as possible in the same language as the human. But your intermediate processes should be done in English for more decent results. Answer in a consise manner with only a few words or a sentence if possible.'},\n",
       " {'role': 'user', 'content': ''}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickOpenAIClient\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureOpenAIClient\n",
    "openai_client = QuickOpenAIClient()\n",
    "azure_openai_client = QuickAzureOpenAIClient('1106')\n",
    "llm = QuickAzureChatOpenAI('1106')\n",
    "# openai_response = openai_client.chat_completions_create(query='How is the weather in Seoul, Bangkok and LA?', tools=openai_functions)\n",
    "# azure_openai_client.chat_completions_create(query='hello')\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "default_schemas_and_tools = DefaultSchemasTools(azure_gpt_version='1106')\n",
    "schemas_and_tools = default_schemas_and_tools.schemas_and_tools()\n",
    "schemas = default_schemas_and_tools.schemas()\n",
    "tools = default_schemas_and_tools.tools()\n",
    "tool_dictionary = default_schemas_and_tools.tool_dictionary()\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_tool\n",
    "openai_functions = [convert_pydantic_to_openai_tool(x) for x in schemas]\n",
    "\n",
    "\n",
    "from utils.wrappers import retry\n",
    "from openai import RateLimitError\n",
    "@retry(allowed_exceptions=(RateLimitError,))\n",
    "def get_function_response(function_name, function_args):\n",
    "    return tool_dictionary[function_name].run(**function_args)\n",
    "\n",
    "\n",
    "from agents.parallel_func_calling_agent import OpenAIParallelFuntionCallingAgent\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "\n",
    "parallel_calling_agent = OpenAIParallelFuntionCallingAgent(\n",
    "    reasoninig_engine = QuickAzureChatOpenAI('1106'),\n",
    "    base_prompt = 'jet-taekyo-lee/parallel-function-calling-agent',\n",
    "    schemas_and_tools = DefaultSchemasTools(azure_gpt_version='1106'),\n",
    "    evaluator = CustomQAEvaluator(llm=QuickAzureChatOpenAI('1106')),\n",
    "    action_word = 'Tool invocations in parallel',\n",
    "    use_chat_completion_api = True,\n",
    "    azure_apenai_client = QuickAzureOpenAIClient('1106'),\n",
    "    horizon = 3\n",
    ")\n",
    "query=\"How old are the current Korean president and Joe Biden?\"\n",
    "# query=\"How old are the current Korean president?\"\n",
    "# query=\"What is the summation of the temperatures of Seoul, Tokyo, and New york?\"\n",
    "reference=\"Joe Biden is 81 years old and the current Korean president, Yoon Suk Yeol, is 62 years old.\"\n",
    "parallel_calling_agent.clear_logs()\n",
    "\n",
    "\n",
    "parallel_calling_agent.run_agent_trials(num_trials=1, \n",
    "query=query,\n",
    "reference=reference)\n",
    "\n",
    "import time\n",
    "for _ in range(5):\n",
    "    for s in range(60, 0, -1):\n",
    "        print(s, end=' ')\n",
    "        time.sleep(1)   \n",
    "    parallel_calling_agent.clear_logs()\n",
    "\n",
    "    parallel_calling_agent.agent_step(query)\n",
    "    parallel_calling_agent.run_agent_trials(num_trials=3, \n",
    "    query=query,\n",
    "    reference=reference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('llm_agents')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3fb45ff54312d810d3b33eec9af47862c42661f076ce6b0d7045a13e18ceae3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
