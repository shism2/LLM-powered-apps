{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are a helpful assistant. Respond to the human as helpfully and accurately as possible in the same language as the human. But your intermediate processes should be done in English for more decent results. Answer in a consise manner with only a few words or a sentence if possible.'}, {'role': 'user', 'content': 'How is the weather in Seoul, Bangkok and LA tomorrow?'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Tool invocations in parallel (step 0): [Tool 0-> OpenWeatherMap(IANA_timezone=Asia/Seoul, Days_from_now=1), Tool 1-> OpenWeatherMap(IANA_timezone=Asia/Bangkok, Days_from_now=1), Tool 2-> OpenWeatherMap(IANA_timezone=America/Los_Angeles, Days_from_now=1)]\n",
      "[INFO] Results in parallel (step 0): [Tool 1-> timezone: Seoul, current time(year-month-day): 2023-11-30, temperature: -2.1299999999999955, humidity: 36, wind_speed: 5.93, weather_summary: Expect a day of partly cloudy with clear spells., Tool 2-> timezone: Bangkok, current time(year-month-day): 2023-11-30, temperature: 31.78000000000003, humidity: 42, wind_speed: 3.65, weather_summary: There will be partly cloudy today., Tool 3-> timezone: Los Angeles, current time(year-month-day): 2023-11-29, temperature: 17.189999999999998, humidity: 43, wind_speed: 4.91, weather_summary: Expect a day of partly cloudy with clear spells.]\n"
     ]
    }
   ],
   "source": [
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickOpenAIClient\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureOpenAIClient\n",
    "openai_client = QuickOpenAIClient()\n",
    "azure_openai_client = QuickAzureOpenAIClient('1106')\n",
    "llm = QuickAzureChatOpenAI('1106')\n",
    "# openai_response = openai_client.chat_completions_create(query='How is the weather in Seoul, Bangkok and LA?', tools=openai_functions)\n",
    "# azure_openai_client.chat_completions_create(query='hello')\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "default_schemas_and_tools = DefaultSchemasTools(azure_gpt_version='1106')\n",
    "schemas_and_tools = default_schemas_and_tools.schemas_and_tools()\n",
    "schemas = default_schemas_and_tools.schemas()\n",
    "tools = default_schemas_and_tools.tools()\n",
    "tool_dictionary = default_schemas_and_tools.tool_dictionary()\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_tool\n",
    "openai_functions = [convert_pydantic_to_openai_tool(x) for x in schemas]\n",
    "\n",
    "\n",
    "from utils.wrappers import retry\n",
    "from openai import RateLimitError\n",
    "@retry(allowed_exceptions=(RateLimitError,))\n",
    "def get_function_response(function_name, function_args):\n",
    "    return tool_dictionary[function_name].run(**function_args)\n",
    "\n",
    "\n",
    "from agents.parallel_func_calling_agent import OpenAIParallelFuntionCallingAgent\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "\n",
    "parallel_calling_agent = OpenAIParallelFuntionCallingAgent(\n",
    "    reasoninig_engine = QuickAzureChatOpenAI('1106'),\n",
    "    base_prompt = 'jet-taekyo-lee/parallel-function-calling-agent',\n",
    "    schemas_and_tools = DefaultSchemasTools(azure_gpt_version='1106'),\n",
    "    evaluator = CustomQAEvaluator(llm=QuickAzureChatOpenAI('1106')),\n",
    "    action_word = 'Tool invocations in parallel',\n",
    "    use_chat_completion_api = True,\n",
    "    azure_apenai_client = QuickAzureOpenAIClient('1106'),\n",
    ")\n",
    "\n",
    "query = 'How is the weather in Seoul, Bangkok and LA? Plus How old are the current Korean president and Joe Biden?'\n",
    "query = 'How is the weather in Seoul, Bangkok and LA tomorrow?'\n",
    "hello_query = 'Hello'\n",
    "\n",
    "\n",
    "msg = parallel_calling_agent.agent_step(query)\n",
    "# msg \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_calling_agent.tool_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "parallel_calling_agent.tool_dictionary['OpenWeatherMap'].run(**json.loads('{\"IANA_timezone\": \"Asia/Seoul\", \"Days_from_now\": 1}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'IANA_timezone': 'Asia/Bangkok'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {tool.__name__: tool for tool in parallel_calling_agent.tools}\n",
    "name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_calling_agent.tools[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('llm_agents')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3fb45ff54312d810d3b33eec9af47862c42661f076ce6b0d7045a13e18ceae3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
