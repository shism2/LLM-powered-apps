{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Envs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, QuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "from configs.hd22_config import HD22Configuration\n",
    "config = HD22Configuration()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, QuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "from configs.hd22_config import HD22Configuration\n",
    "config = HD22Configuration()\n",
    "\n",
    "#### ReAct Agent\n",
    "from agents.react.react_agent import ReActAgent\n",
    "\n",
    "GPT_VER = '0613'\n",
    "react_agent = ReActAgent(reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER), \n",
    "                        base_prompt=\"hwchase17/react-multi-input-json\", \n",
    "                        schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER), \n",
    "                        evaluator=CustomQAEvaluator(llm=QuickAzureChatOpenAI(version='1106')), \n",
    "                        stop_words=[\"Observation\"], \n",
    "                        thought_word= 'Thought', \n",
    "                        action_word='Action',\n",
    "                        file_logging=True,\n",
    "                        horizon=5)\n",
    "\n",
    "query = \"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\"\n",
    "reference = \"The former former president of Korea is older. The sum of their age is 99.\"\n",
    "num_trials = 2\n",
    "\n",
    "react_agent.clear_logs()\n",
    "# answer = react_agent.runnable_agent_step.invoke(query)\n",
    "# answer = react_agent.runnable_agent_episode.invoke(query, **{'reference':reference})\n",
    "answer = react_agent.runnable_agent_trial.invoke(query, **{'num_trials':num_trials, 'reference':reference})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflexion ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, QuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "from configs.hd22_config import HD22Configuration\n",
    "config = HD22Configuration()\n",
    "\n",
    "#### Reflexion Agent\n",
    "from agents.react.react_agent_with_reflexion import ReActWithReflexionAgent\n",
    "from agents.react.react_fewshot_examples import REACT_REFLECTION_HEADER, REACT_REFLECTIONS\n",
    "from chains.reflexion_chains import BaseReflexionChain\n",
    "\n",
    "GPT_VER = '0613'   \n",
    "reflexion_chains = BaseReflexionChain(\n",
    "                    reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER),\n",
    "                    prompt=\"jet-taekyo-lee/experimental-reflextion\", \n",
    "                    schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "                    reflexion_examples=REACT_REFLECTIONS\n",
    "                    )\n",
    "\n",
    "reflexion_prompt = \"jet-taekyo-lee/reflexion-react\"\n",
    "reflexion_agent = ReActWithReflexionAgent(\n",
    "                        reflexion_chain = reflexion_chains,\n",
    "                        reflexion_header = REACT_REFLECTION_HEADER,\n",
    "                        reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER), \n",
    "                        base_prompt=\"hwchase17/react-multi-input-json\", \n",
    "                        schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER), \n",
    "                        evaluator=CustomQAEvaluator(llm=QuickAzureChatOpenAI(version='1106')), \n",
    "                        stop_words=[\"Observation\"], \n",
    "                        thought_word= 'Thought', \n",
    "                        action_word='Action',\n",
    "                        file_logging=True,\n",
    "                        horizon=5)\n",
    "\n",
    "\n",
    "query = \"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\"\n",
    "reference = \"The former former president of Korea is older. The sum of their age is 99.\"\n",
    "num_trials = 2\n",
    "\n",
    "reflexion_agent.clear_logs()\n",
    "# answer = reflexion_agent.runnable_agent_step.invoke(query)\n",
    "# answer = reflexion_agent.runnable_agent_episode.invoke(query, **{'reference':reference})\n",
    "answer = reflexion_agent.runnable_agent_trial.invoke(query, **{'num_trials':num_trials, 'reference':reference})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Regacy agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, QuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "from configs.hd22_config import HD22Configuration\n",
    "config = HD22Configuration()\n",
    "\n",
    "# #### OepnAI Agent\n",
    "GPT_VER = '0613' \n",
    "from agents.openai_legacy.openai_legacy_agent import OpenAILegacyAgent\n",
    "openai_agent = OpenAILegacyAgent(\n",
    "    reasoninig_engine = QuickAzureChatOpenAI(version=GPT_VER),\n",
    "    base_prompt = \"jet-taekyo-lee/openai-function-calling-agent\",\n",
    "    schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "    evaluator = CustomQAEvaluator(llm=QuickAzureChatOpenAI(version='1106')),\n",
    "    action_word = 'Invoking',\n",
    "    horizon = 5)\n",
    "\n",
    "\n",
    "query = \"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\"\n",
    "reference = \"The former former president of Korea is older. The sum of their age is 99.\"\n",
    "num_trials = 2\n",
    "\n",
    "openai_agent.clear_logs()\n",
    "# answer = openai_agent.runnable_agent_step.invoke(query)\n",
    "# answer = openai_agent.runnable_agent_episode.invoke(query, **{'reference':reference})\n",
    "answer = openai_agent.runnable_agent_trial.invoke(query, **{'num_trials':num_trials, 'reference':reference})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflexion OpenAI Legacy agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, QuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "from configs.hd22_config import HD22Configuration\n",
    "config = HD22Configuration()\n",
    "\n",
    "# # #### Reflexion OepnAI Agent\n",
    "from agents.openai_legacy.openai_legacy_with_reflexion_agent import OpenAILegacyWithReflexionAgent\n",
    "from agents.openai_legacy.openai_legacy_fewshot_examples import OPENAI_LEGACY_REFLECTIONS, OPENAI_LEGACY_REFLECTION_HEADER\n",
    "from chains.reflexion_chains import BaseReflexionChain\n",
    "\n",
    "\n",
    "GPT_VER = '0613'    \n",
    "openai_legacy_reflexion_chains = BaseReflexionChain(\n",
    "                    reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER),\n",
    "                    prompt=\"jet-taekyo-lee/openai-reflexion-chain-prompt\", \n",
    "                    schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "                    reflexion_examples=OPENAI_LEGACY_REFLECTIONS\n",
    "                    )\n",
    "\n",
    "\n",
    "openai_legacy_reflexion_agent = OpenAILegacyWithReflexionAgent(\n",
    "                        reflexion_chain = openai_legacy_reflexion_chains,\n",
    "                        reflexion_header = OPENAI_LEGACY_REFLECTION_HEADER,\n",
    "                        reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER), \n",
    "                        base_prompt=\"jet-taekyo-lee/rexlexion-openai-function-calling-agent\", \n",
    "                        schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "                        evaluator=CustomQAEvaluator(llm=QuickAzureChatOpenAI(version='1106')),\n",
    "                        action_word='Invoking',\n",
    "                        file_logging=True,\n",
    "                        horizon = 5)\n",
    "\n",
    "\n",
    "query = \"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\"\n",
    "reference = \"The former former president of Korea is older. The sum of their age is 99.\"\n",
    "num_trials = 2\n",
    "\n",
    "openai_legacy_reflexion_agent.clear_logs()\n",
    "# answer = openai_legacy_reflexion_agent.runnable_agent_step.invoke(query)\n",
    "# answer = openai_legacy_reflexion_agent.runnable_agent_episode.invoke(query, **{'reference':reference})\n",
    "answer = openai_legacy_reflexion_agent.runnable_agent_trial.invoke(query, **{'num_trials':num_trials, 'reference':reference})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Function Calling agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Query: Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\n",
      "[INFO] Trial 1\n",
      "[INFO] (step 1-action) Tool invocations in parallel: [Tool 1-> YDCSearch(query=former president of Korea age), Tool 2-> YDCSearch(query=MLB American League MVP last season age)]\n",
      "[INFO] (step 1-observation) :: [Tool 1-> The current former president of South Korea is Moon Jae-in, who was born on January 24, 1953. As of my knowledge cutoff in 2023, Moon Jae-in would be 70 years old., Tool 2-> The American League MVP for the 2022 MLB season was Aaron Judge of the New York Yankees. Aaron Judge was born on April 26, 1992, which made him 30 years old during the 2022 season when he won the MVP award.]\n",
      "[INFO] (step 2-action) Tool invocations in parallel: Now I can answer directly without resorting to any tool.\n",
      "[INFO] Answer: Moon Jae-in, the former president of Korea, is older than Aaron Judge, the MLB American League MVP of the last season. If you sum up the ages of the two, the result is 100 years.\n",
      "[INFO] Jugdement: Your answer is incorrect. The correct answer is \"The former former president of Korea is older. The sum of their age is 99.\"\n",
      "[INFO] Trial 2\n",
      "[INFO] (step 1-action) Tool invocations in parallel: [Tool 1-> YDCSearch(query=former President of Korea age), Tool 2-> YDCSearch(query=2022 MLB American League MVP age)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RateLimitError for get_function_observation. -----> Will automatically retry 20 seconds later.\n",
      "20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 RateLimitError for get_function_observation. -----> Will automatically retry 20 seconds later.\n",
      "20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, AsyncQuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "from configs.hd22_config import HD22Configuration\n",
    "import asyncio\n",
    "config = HD22Configuration()\n",
    "\n",
    "#### Parallel Function Calling Agent\n",
    "GPT_VER = '1106' \n",
    "from agents.openai_parallel.openai_parallel_agent import OpenAIParallelAgent\n",
    "\n",
    "openai_parallel_agent = OpenAIParallelAgent(\n",
    "    reasoninig_engine = QuickAzureChatOpenAI(version=GPT_VER),\n",
    "    base_prompt = 'jet-taekyo-lee/parallel-function-calling-agent',\n",
    "    schemas_and_tools = DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "    evaluator = CustomQAEvaluator(llm=QuickAzureChatOpenAI('0613')),\n",
    "    action_word = 'Tool invocations in parallel',\n",
    "    observation_word = 'Tool-invocations results in parallel',\n",
    "    use_chat_completion_api = True,\n",
    "    azure_apenai_client = AsyncQuickAzureOpenAIClient(GPT_VER),\n",
    "    horizon = 5\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "query = \"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\"\n",
    "reference = \"The former former president of Korea is older. The sum of their age is 99.\"\n",
    "num_trials = 2\n",
    "\n",
    "\n",
    "# openai_parallel_agent.clear_logs()\n",
    "\n",
    "# await openai_parallel_agent.runnable_agent_step.ainvoke(query)\n",
    "# await openai_parallel_agent.runnable_agent_episode.ainvoke(query, **{'reference':reference})\n",
    "await openai_parallel_agent.runnable_agent_trial.ainvoke(query, **{'reference':reference, 'num_trials':num_trials})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, AsyncQuickAzureOpenAIClient\n",
    "# from tools.get_tools import DefaultSchemasTools\n",
    "# from langchain import hub\n",
    "# from utils.load_envs import Environ\n",
    "# from chains.qa_evaluators import CustomQAEvaluator\n",
    "# from configs.hd22_config import HD22Configuration\n",
    "# import asyncio\n",
    "# config = HD22Configuration()\n",
    "\n",
    "# #### Parallel Function Calling Agent\n",
    "# GPT_VER = '1106' \n",
    "# from agents.openai_parallel.openai_parallel_agent import OpenAIParallelAgent\n",
    "\n",
    "# openai_parallel_agent = OpenAIParallelAgent(\n",
    "#     reasoninig_engine = QuickAzureChatOpenAI(version=GPT_VER),\n",
    "#     base_prompt = 'jet-taekyo-lee/parallel-function-calling-agent',\n",
    "#     schemas_and_tools = DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "#     evaluator = CustomQAEvaluator(llm=QuickAzureChatOpenAI('0613')),\n",
    "#     action_word = 'Tool invocations in parallel',\n",
    "#     observation_word = 'Tool-invocations results in parallel',\n",
    "#     use_chat_completion_api = True,\n",
    "#     azure_apenai_client = AsyncQuickAzureOpenAIClient(GPT_VER),\n",
    "#     horizon = 5\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# query = \"Did the Yankees win more than 100 games last season?\"\n",
    "# reference = \"No, They did not win more than 100 games last season.\"\n",
    "# num_trials = 2\n",
    "\n",
    "\n",
    "# # openai_parallel_agent.clear_logs()\n",
    "\n",
    "# # await openai_parallel_agent.runnable_agent_step.ainvoke(query)\n",
    "# # await openai_parallel_agent.runnable_agent_episode.ainvoke(query, **{'reference':reference})\n",
    "# await openai_parallel_agent.runnable_agent_trial.ainvoke(query, **{'reference':reference, 'num_trials':num_trials})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflexion + Parallel Function Calling agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, AsyncQuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "import asyncio\n",
    "config = HD22Configuration()\n",
    "\n",
    "#### Reflexion + Parallel Function Calling Agent\n",
    "from chains.reflexion_chains import BaseReflexionChain\n",
    "from agents.openai_parallel.openai_parallel_with_reflexion_agent import OpenAIParallelWithReflexionAgent\n",
    "from agents.openai_parallel.openai_parallel_fewshot_examples import OPENAI_PARALLEL_REFLECTIONS, OPENAI_PARALLEL_REFLECTION_HEADER\n",
    "\n",
    "GPT_VER = '1106'    \n",
    "openai_parallel_reflexion_chains = BaseReflexionChain(\n",
    "                    reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER),\n",
    "                    prompt=\"jet-taekyo-lee/openai-parallel-calling-reflexion-chain-prompt\", \n",
    "                    schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "                    reflexion_examples=OPENAI_PARALLEL_REFLECTIONS\n",
    "                    )\n",
    "\n",
    "\n",
    "openai_parallel_reflexion_agent = OpenAIParallelWithReflexionAgent(\n",
    "                        reflexion_chain = openai_parallel_reflexion_chains,\n",
    "                        reflexion_header = OPENAI_PARALLEL_REFLECTION_HEADER,\n",
    "                        reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER), \n",
    "                        base_prompt=\"jet-taekyo-lee/reflexion-openai-parallel-calling-agent\", \n",
    "                        schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "                        evaluator=CustomQAEvaluator(llm=QuickAzureChatOpenAI(version='1106')),\n",
    "                        action_word = 'Tool invocations in parallel',\n",
    "                        observation_word = 'Tool-invocations results in parallel',\n",
    "                        use_chat_completion_api = True,\n",
    "                        azure_apenai_client = AsyncQuickAzureOpenAIClient(GPT_VER),\n",
    "                        file_logging=True,\n",
    "                        horizon = 5)\n",
    "\n",
    "\n",
    "query = \"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\"\n",
    "reference = \"The former former president of Korea is older. The sum of their age is 99.\"\n",
    "num_trials = 2\n",
    "\n",
    "\n",
    "\n",
    "openai_parallel_reflexion_agent.clear_logs()\n",
    "# await openai_parallel_reflexion_agent.runnable_agent_step.ainvoke(query)\n",
    "# await openai_parallel_reflexion_agent.runnable_agent_episode.ainvoke(query, **{'reference':reference})\n",
    "await openai_parallel_reflexion_agent.runnable_agent_trial.ainvoke(query, **{'reference':reference, 'num_trials':num_trials})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('llm_agents')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3fb45ff54312d810d3b33eec9af47862c42661f076ce6b0d7045a13e18ceae3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
