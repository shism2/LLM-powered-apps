{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Envs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, QuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "from configs.hd22_config import HD22Configuration\n",
    "config = HD22Configuration()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Query: Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\n",
      "[INFO] Trial 1\n",
      "[INFO] Thought 1: I need to find out who the former president of Korea is and who the MLB American League MVP of the last season is. I'll start with the former president of Korea.\n",
      "[INFO] Action 1: YDCSearch(query='former president of Korea')\n",
      "[INFO] Observation 1: The most recent former president of South Korea is Moon Jae-In, who served from 2017 to 2022.\n",
      "[INFO] Thought 2: Now I need to find out Moon Jae-In's age.\n",
      "[INFO] Action 2: YDCSearch(query='Moon Jae-In age')\n",
      "[INFO] Observation 2: Moon Jae-in was born on January 24, 1953.\n",
      "[INFO] Thought 3: I need to calculate Moon Jae-In's age based on his birth year. I'll use the current year to do this.\n",
      "[INFO] Action 3: GetDatetime(IANA_timezone='Asia/Seoul')\n",
      "[INFO] Observation 3: timezone: Asia/Seoul, current time(year-month-day-hour-minute): 2023-12-1-20-35\n",
      "[INFO] Jugdement: You failed to provide an answer because you exceeded the permitted number of reasoning steps. You must give an answer within 3 steps.\n",
      "[INFO] Trial 2\n",
      "[INFO] Thought 1: I need to find out who the former president of Korea is and who the MLB American League MVP of the last season is. Then, I need to find out their ages. I'll start by finding out who the former president of Korea is.\n",
      "[INFO] Action 1: YDCSearch(query='former president of Korea')\n",
      "[INFO] Observation 1: The most recent former president of South Korea is Moon Jae-In, who served from 2017 to 2022.\n",
      "[INFO] Thought 2: Now I know that the former president of Korea is Moon Jae-In. Next, I need to find out his age.\n",
      "[INFO] Action 2: YDCSearch(query='Moon Jae-In age')\n",
      "[INFO] Observation 2: Moon Jae-in was born on January 24, 1953.\n",
      "[INFO] Thought 3: Now I know that Moon Jae-In was born on January 24, 1953. I can calculate his age using the current year. But before that, I need to find out who the MLB American League MVP of the last season is.\n",
      "[INFO] Action 3: YDCSearch(query='MLB American League MVP last season')\n",
      "[INFO] Observation 3: The Most Valuable Player in the American League for the 2023 season was Shohei Ohtani from the LA Angels.\n",
      "[INFO] Jugdement: You failed to provide an answer because you exceeded the permitted number of reasoning steps. You must give an answer within 3 steps.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, QuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "config = HD22Configuration()\n",
    "\n",
    "#### ReAct Agent\n",
    "from agents.react.react_agent import ReActAgent\n",
    "\n",
    "GPT_VER = '0613'\n",
    "react_agent = ReActAgent(reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER), \n",
    "                        base_prompt=\"hwchase17/react-multi-input-json\", \n",
    "                        schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER), \n",
    "                        evaluator=CustomQAEvaluator(llm=QuickAzureChatOpenAI(version='1106')), \n",
    "                        stop_words=[\"Observation\"], \n",
    "                        thought_word= 'Thought', \n",
    "                        action_word='Action',\n",
    "                        file_logging=True,\n",
    "                        horizon=3)\n",
    "\n",
    "\n",
    "\n",
    "react_agent.clear_logs()\n",
    "react_agent.run_agent_trials(num_trials=2, \n",
    "query=\"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\",\n",
    "reference=\"The former former president of Korea is older. The sum of their age is 99.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflexion ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Query: Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\n",
      "[INFO] Trial 1\n",
      "[INFO] Thought 1: I need to find out who the former president of Korea is and who the MLB American League MVP of the last season is. Then, I need to find out their ages. I'll start by finding out who the former president of Korea is.\n",
      "[INFO] Action 1: YDCSearch(query='former president of Korea')\n",
      "[INFO] Observation 1: The most recent former president of South Korea is Moon Jae-In, who served from 2017 to 2022.\n",
      "[INFO] Thought 2: Now that I know the former president of Korea is Moon Jae-In, I need to find out his age.\n",
      "[INFO] Action 2: YDCSearch(query='Moon Jae-In age')\n",
      "[INFO] Observation 2: Moon Jae-in was born on January 24, 1953.\n",
      "[INFO] Thought 3: Now that I know Moon Jae-In was born on January 24, 1953, I can calculate his age. I'll use the current year to do this.\n",
      "[INFO] Action 3: GetDatetime(IANA_timezone='Asia/Seoul')\n",
      "[INFO] Observation 3: timezone: Asia/Seoul, current time(year-month-day-hour-minute): 2023-12-1-20-36\n",
      "[INFO] Jugdement: You failed to provide an answer because you exceeded the permitted number of reasoning steps. You must give an answer within 3 steps.\n",
      "[INFO] Trial 2\n",
      "[INFO] Reflexion......\n",
      "[INFO] You have attempted to answer following question before and failed. The following reflection(s) give a plan to avoid failing to answer the question in the same way you did previously. Use them to improve your strategy of correctly answering the given question.\n",
      "- In this trial, I failed to provide an answer within the allocated reasoning steps because I attempted to gather all the necessary information before making any calculations. I spent two steps identifying and verifying the age of the former president of Korea, Moon Jae-In, and then used a third step to get the current date for age calculation. However, I didn't even start gathering information about the MLB American League MVP of the last season. \n",
      "\n",
      "In the future, I should prioritize gathering the necessary information first, and then perform calculations. For instance, I could have used the first two steps to identify the former president of Korea and the MLB American League MVP of the last season, and then used the third step to search for their ages. If the ages are not readily available, I could at least provide partial information within the given reasoning steps.\n",
      "[INFO] Thought 1: I need to find out who the former president of Korea is and who the MLB American League MVP of the last season is. I'll start with the former president of Korea.\n",
      "[INFO] Action 1: YDCSearch(query='former president of Korea')\n",
      "[INFO] Observation 1: The most recent former president of South Korea is Moon Jae-In, who served from 2017 to 2022.\n",
      "[INFO] Thought 2: Now I need to find out Moon Jae-In's age.\n",
      "[INFO] Action 2: YDCSearch(query='Moon Jae-In age')\n",
      "[INFO] Observation 2: Moon Jae-in was born on January 24, 1953.\n",
      "[INFO] Thought 3: Now I need to calculate Moon Jae-In's age.\n",
      "[INFO] Action 3: PythonREPL(command='from datetime import datetime\n",
      "print((datetime.now() - datetime(1953, 1, 24)).days // 365)')\n",
      "Python REPL can execute arbitrary code. Use with caution.\n",
      "[INFO] Observation 3: 70\n",
      "[INFO] Jugdement: You failed to provide an answer because you exceeded the permitted number of reasoning steps. You must give an answer within 3 steps.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, QuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "config = HD22Configuration()\n",
    "\n",
    "#### Reflexion Agent\n",
    "from agents.react.react_agent_with_reflexion import ReActWithReflexionAgent\n",
    "from agents.react.react_fewshot_examples import REACT_REFLECTION_HEADER, REACT_REFLECTIONS\n",
    "from chains.reflexion_chains import BaseReflexionChain\n",
    "\n",
    "GPT_VER = '0613'   \n",
    "reflexion_chains = BaseReflexionChain(\n",
    "                    reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER),\n",
    "                    prompt=\"jet-taekyo-lee/experimental-reflextion\", \n",
    "                    schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "                    reflexion_examples=REACT_REFLECTIONS\n",
    "                    )\n",
    "\n",
    "reflexion_prompt = \"jet-taekyo-lee/reflexion-react\"\n",
    "reflexion_agent = ReActWithReflexionAgent(\n",
    "                        reflexion_chain = reflexion_chains,\n",
    "                        reflexion_header = REACT_REFLECTION_HEADER,\n",
    "                        reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER), \n",
    "                        base_prompt=\"hwchase17/react-multi-input-json\", \n",
    "                        schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER), \n",
    "                        evaluator=CustomQAEvaluator(llm=QuickAzureChatOpenAI(version='1106')), \n",
    "                        stop_words=[\"Observation\"], \n",
    "                        thought_word= 'Thought', \n",
    "                        action_word='Action',\n",
    "                        file_logging=True,\n",
    "                        horizon=3)\n",
    "\n",
    "\n",
    "\n",
    "reflexion_agent.clear_logs()\n",
    "reflexion_agent.run_agent_trials(num_trials=2, \n",
    "query=\"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\",\n",
    "reference=\"The former former president of Korea is older. The sum of their age is 99.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Regacy agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Query: Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\n",
      "[INFO] Trial 1\n",
      "[INFO] Invoking 1: YDCSearch(query='former president of Korea age')\n",
      "[INFO] Observation 1: The former president of South Korea, Moon Jae-in, was born on January 24, 1953. As of 2022, he is 69 years old. The current president, Yoon Suk Yeol, was born on December 18, 1960, making him 62 years old as of 2022.\n",
      "[INFO] Invoking 2: YDCSearch(query='MLB American League MVP last season age')\n",
      "[INFO] Observation 2: The American League MVP for the 2023 season was Shohei Ohtani from the Los Angeles Angels. He was born on July 5, 1994, which would have made him 29 years old during the 2023 season.\n",
      "[INFO] Invoking 3: PythonREPL(command='print(69 + 29)')\n",
      "[INFO] Observation 3: 98\n",
      "[INFO] Jugdement: You failed to provide an answer because you exceeded the permitted number of reasoning steps. You must give an answer within 3 steps.\n",
      "[INFO] Trial 2\n",
      "[INFO] Invoking 1: YDCSearch(query='former president of Korea age')\n",
      "[INFO] Observation 1: The most recent former president of South Korea, Moon Jae-in, was born on January 24, 1953, which makes him 69 years old as of 2022.\n",
      "[INFO] Invoking 2: YDCSearch(query='MLB American League MVP 2021 age')\n",
      "[INFO] Observation 2: Shohei Ohtani, who won the American League MVP in 2021, was born on July 5, 1994, which made him 27 years old at the time he received the award.\n",
      "[INFO] Invoking 3: PythonREPL(command='print(69 + 27)')\n",
      "[INFO] Observation 3: 96\n",
      "[INFO] Jugdement: You failed to provide an answer because you exceeded the permitted number of reasoning steps. You must give an answer within 3 steps.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, QuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "config = HD22Configuration()\n",
    "\n",
    "# #### OepnAI Agent\n",
    "GPT_VER = '0613' \n",
    "from agents.openai_legacy.openai_legacy_agent import OpenAILegacyAgent\n",
    "openai_agent = OpenAILegacyAgent(\n",
    "    reasoninig_engine = QuickAzureChatOpenAI(version=GPT_VER),\n",
    "    base_prompt = \"jet-taekyo-lee/openai-function-calling-agent\",\n",
    "    schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "    evaluator = CustomQAEvaluator(llm=QuickAzureChatOpenAI(version='1106')),\n",
    "    action_word = 'Invoking',\n",
    "    horizon = 3)\n",
    "\n",
    "openai_agent.clear_logs()\n",
    "openai_agent.run_agent_trials(num_trials=2, \n",
    "query=\"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\",\n",
    "reference=\"The former former president of Korea is older. The sum of their age is 99.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflexion OpenAI Legacy agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Query: Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\n",
      "[INFO] Trial 1\n",
      "[INFO] Invoking 1: YDCSearch(query='former president of Korea age')\n",
      "[INFO] Observation 1: The context provided does not specify which former president of Korea's age you are asking about. There have been multiple former presidents of Korea. Please provide more specific information.\n",
      "[INFO] Invoking 2: I'm sorry, but there have been multiple former presidents of Korea. Could you please specify which one you're referring to?\n",
      "[INFO] Answer: I'm sorry, but there have been multiple former presidents of Korea. Could you please specify which one you're referring to?\n",
      "[INFO] Jugdement: Your answer is incorrect. The correct answer is \"The former former president of Korea is older. The sum of their age is 99.\"\n",
      "[INFO] Trial 2\n",
      "[INFO] Reflexion......\n",
      "[INFO] You have attempted to answer following question before and failed. The following reflection(s) give a plan to avoid failing to answer the question in the same way you did previously. Use them to improve your strategy of correctly answering the given question.\n",
      "- The failure in this trial was due to the ambiguity in the query. The term \"former president of Korea\" could refer to any of the past presidents, and without specific information, it's impossible to provide an accurate answer. In the future, when faced with a similar query, I should ask for clarification to specify which former president's age is being referred to. Additionally, I should have also searched for the age of the MLB American League MVP of the last season to provide a more complete response.\n",
      "[INFO] Invoking 1: YDCSearch(query='MLB American League MVP of the last season')\n",
      "[INFO] Observation 1: The American League Most Valuable Player (MVP) for the last season (2023) was Shohei Ohtani from the Los Angeles Angels.\n",
      "[INFO] Invoking 2: YDCSearch(query='Shohei Ohtani birthdate')\n",
      "[INFO] Observation 2: Shohei Ohtani was born on July 5, 1994.\n",
      "[INFO] Invoking 3: PythonREPL(command='from datetime import datetime\\nprint((datetime.now() - datetime(1994, 7, 5)).days // 365)')\n",
      "[INFO] Observation 3: 29\n",
      "[INFO] Jugdement: You failed to provide an answer because you exceeded the permitted number of reasoning steps. You must give an answer within 3 steps.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, QuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "config = HD22Configuration()\n",
    "\n",
    "# # #### Reflexion OepnAI Agent\n",
    "from agents.openai_legacy.openai_legacy_with_reflexion_agent import OpenAILegacyWithReflexionAgent\n",
    "from agents.openai_legacy.openai_legacy_fewshot_examples import OPENAI_LEGACY_REFLECTIONS, OPENAI_LEGACY_REFLECTION_HEADER\n",
    "from chains.reflexion_chains import BaseReflexionChain\n",
    "\n",
    "\n",
    "GPT_VER = '0613'    \n",
    "openai_legacy_reflexion_chains = BaseReflexionChain(\n",
    "                    reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER),\n",
    "                    prompt=\"jet-taekyo-lee/openai-reflexion-chain-prompt\", \n",
    "                    schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "                    reflexion_examples=OPENAI_LEGACY_REFLECTIONS\n",
    "                    )\n",
    "\n",
    "\n",
    "openai_legacy_reflexion_agent = OpenAILegacyWithReflexionAgent(\n",
    "                        reflexion_chain = openai_legacy_reflexion_chains,\n",
    "                        reflexion_header = OPENAI_LEGACY_REFLECTION_HEADER,\n",
    "                        reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER), \n",
    "                        base_prompt=\"jet-taekyo-lee/rexlexion-openai-function-calling-agent\", \n",
    "                        schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "                        evaluator=CustomQAEvaluator(llm=QuickAzureChatOpenAI(version='1106')),\n",
    "                        action_word='Invoking',\n",
    "                        file_logging=True,\n",
    "                        horizon = 3)\n",
    "\n",
    "openai_legacy_reflexion_agent.clear_logs()\n",
    "openai_legacy_reflexion_agent.run_agent_trials(num_trials=2, \n",
    "query=\"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\",\n",
    "reference=\"The former former president of Korea is older. The sum of their age is 99.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Function Calling agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Query: Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\n",
      "[INFO] Trial 1\n",
      "[INFO] (step 1-action) Tool invocations in parallel: [Tool 1-> YDCSearch(query=former president of Korea age), Tool 2-> YDCSearch(query=MLB American League MVP last season age)]\n",
      "[INFO] (step 1-observation) :: [Tool 1-> As of my knowledge cutoff date in April 2023, the most recent former president of South Korea is Moon Jae-in, who was born on January 24, 1953. Therefore, as of April 2023, Moon Jae-in would be 70 years old. Please note that ages will change as time passes, so you may need to calculate the current age based on the birth date provided., Tool 2-> The American League MVP for the 2023 season was Shohei Ohtani of the Los Angeles Angels (LAA). His age at the time of receiving the award is not explicitly stated in the provided context, but since he was born on July 5, 1994, he would have been 29 years old during the 2023 MLB season when he received the MVP award.]\n",
      "[INFO] (step 2-action) Tool invocations in parallel: Now I can answer directly without resorting to any tool.\n",
      "[INFO] Answer: Der ehemalige Präsident von Korea, Moon Jae-in, ist älter als der MVP der American League der MLB. Wenn man die alter der beiden summiert, ergibt sich 70 (Moon Jae-in) + 29 (Shohei Ohtani) = 99 Jahre.\n",
      "[INFO] Jugdement: Your answer is correct.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, AsyncQuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "import asyncio\n",
    "config = HD22Configuration()\n",
    "\n",
    "#### Parallel Function Calling Agent\n",
    "GPT_VER = '1106' \n",
    "from agents.openai_parallel.openai_parallel_agent import OpenAIParallelAgent\n",
    "\n",
    "openai_parallel_agent = OpenAIParallelAgent(\n",
    "    reasoninig_engine = QuickAzureChatOpenAI(version=GPT_VER),\n",
    "    base_prompt = 'jet-taekyo-lee/parallel-function-calling-agent',\n",
    "    schemas_and_tools = DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "    evaluator = CustomQAEvaluator(llm=QuickAzureChatOpenAI('0613')),\n",
    "    action_word = 'Tool invocations in parallel',\n",
    "    observation_word = 'Tool-invocations results in parallel',\n",
    "    use_chat_completion_api = True,\n",
    "    azure_apenai_client = AsyncQuickAzureOpenAIClient(GPT_VER),\n",
    "    horizon = 3\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "openai_parallel_agent.clear_logs()\n",
    "await openai_parallel_agent._run_agent_trials_async(num_trials=2, \n",
    "query=\"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\",\n",
    "reference=\"The former former president of Korea is older. The sum of their age is 99.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflexion + Parallel Function Calling agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Query: Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\n",
      "[INFO] Trial 1\n",
      "[INFO] (step 1-action) Tool invocations in parallel: [Tool 1-> YDCSearch(query=former president of South Korea), Tool 2-> YDCSearch(query=MLB American League MVP last season)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RateLimitError for get_function_observation. -----> Will automatically retry 20 seconds later.\n",
      "20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] (step 1-observation) :: [Tool 1-> Park Geun-hye is a former president of South Korea who served as the 11th president from 2013 until her impeachment in 2017. She was the first woman to be elected as president of South Korea and the first female president popularly elected as head of state in East Asia. Her presidency ended when she was impeached and later convicted on charges related to corruption. After serving a portion of her prison sentence, Park Geun-hye was released from prison following a pardon in December 2021., Tool 2-> The American League MVP for the 2023 season was Shohei Ohtani of the LA Angels.]\n",
      "[INFO] (step 2-action) Tool invocations in parallel: [Tool 1-> YDCSearch(query=Park Geun-hye age), Tool 2-> YDCSearch(query=Shohei Ohtani age)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RateLimitError for get_function_observation. -----> Will automatically retry 20 seconds later.\n",
      "20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] (step 2-observation) :: [Tool 1-> Park Geun-hye was born on February 2, 1952. As of my knowledge cutoff in 2023, she would be 71 years old., Tool 2-> Shohei Ohtani is 29 years old.]\n",
      "[INFO] (step 3-action) Tool invocations in parallel: [Tool 1-> PythonREPL(command=print(71 + 29))]\n",
      "[INFO] (step 3-observation) :: [Tool 1-> 100]\n",
      "[INFO] Jugdement: You failed to provide an answer because you exceeded the permitted number of reasoning steps. You must give an answer within 3 steps.\n",
      "[INFO] Trial 2\n",
      "[INFO] Reflexion......\n",
      "[INFO] You have attempted to answer following question before and failed. The following reflection(s) give a plan to avoid failing to answer the question in the same way you did previously. Use them to improve your strategy of correctly answering the given question.\n",
      "- Reflection: The failure in the previous trial was due to exceeding the permitted number of reasoning steps before providing an answer. The process of identifying the individuals and their ages was correct, but the final step of summing their ages and determining who is older should have been combined into a single step to comply with the three-step limit.\n",
      "\n",
      "New Strategy: To avoid a similar error in future attempts, I will streamline the process by combining the final calculation and the provision of the answer into one step. This will ensure that the response is given within the allotted number of steps. Additionally, I will ensure that all necessary information is gathered and processed efficiently within the constraints of the reasoning trial. Here is the revised plan:\n",
      "\n",
      "1. Use the YDCSearch tool to identify the former president of South Korea and the MLB American League MVP of the last season.\n",
      "2. Use the YDCSearch tool to find the ages of both individuals.\n",
      "3. Calculate the sum of their ages and determine who is older, then provide the answer within the same step.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RateLimitError for _invoke_agent_action_async. -----> Will automatically retry 20 seconds later.\n",
      "20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] (step 1-action) Tool invocations in parallel: [Tool 1-> YDCSearch(query=former president of South Korea), Tool 2-> YDCSearch(query=MLB American League MVP 2022)]\n",
      "[INFO] (step 1-observation) :: [Tool 1-> Park Geun-hye is a former president of South Korea who served as the 11th president from 2013 until her impeachment in 2017. She was the first woman to be elected as president of South Korea and the first female president popularly elected as head of state in East Asia. Her presidency ended when she was impeached and subsequently convicted on charges related to corruption. After spending nearly five years in prison, Park Geun-hye was released in December 2021 following a presidential pardon., Tool 2-> The American League MVP for the 2022 MLB season was Aaron Judge of the New York Yankees.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RateLimitError for _invoke_agent_action_async. -----> Will automatically retry 20 seconds later.\n",
      "20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] (step 2-action) Tool invocations in parallel: [Tool 1-> YDCSearch(query=Park Geun-hye age), Tool 2-> YDCSearch(query=Aaron Judge age)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RateLimitError for get_function_observation. -----> Will automatically retry 20 seconds later.\n",
      "20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] (step 2-observation) :: [Tool 1-> Park Geun-hye was born on February 2, 1952. As of my knowledge cutoff in 2023, she would be 71 years old., Tool 2-> Aaron Judge is 31 years old.]\n",
      "[INFO] (step 3-action) Tool invocations in parallel: Now I can answer directly without resorting to any tool.\n",
      "[INFO] Answer: 선생님께서 물으신 대로 하여, 한국의 전 대통령은 만 71세이며, 2022년 MLB 아메리칸 리그 MVP는 만 31세입니다. 두 사람의 나이를 합치면 102세가 되며, 한국의 전 대통령이 MLB 아메리칸 리그 MVP보다 나이가 많습니다.\n",
      "[INFO] Jugdement: Your answer is incorrect. The correct answer is \"The former former president of Korea is older. The sum of their age is 99.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, AsyncQuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "import asyncio\n",
    "config = HD22Configuration()\n",
    "\n",
    "#### Reflexion + Parallel Function Calling Agent\n",
    "from chains.reflexion_chains import BaseReflexionChain\n",
    "from agents.openai_parallel.openai_parallel_with_reflexion_agent import OpenAIParallelWithReflexionAgent\n",
    "from agents.openai_parallel.openai_parallel_fewshot_examples import OPENAI_PARALLEL_REFLECTIONS, OPENAI_PARALLEL_REFLECTION_HEADER\n",
    "\n",
    "GPT_VER = '1106'    \n",
    "openai_parallel_reflexion_chains = BaseReflexionChain(\n",
    "                    reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER),\n",
    "                    prompt=\"jet-taekyo-lee/openai-parallel-calling-reflexion-chain-prompt\", \n",
    "                    schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "                    reflexion_examples=OPENAI_PARALLEL_REFLECTIONS\n",
    "                    )\n",
    "\n",
    "\n",
    "openai_parallel_reflexion_agent = OpenAIParallelWithReflexionAgent(\n",
    "                        reflexion_chain = openai_parallel_reflexion_chains,\n",
    "                        reflexion_header = OPENAI_PARALLEL_REFLECTION_HEADER,\n",
    "                        reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER), \n",
    "                        base_prompt=\"jet-taekyo-lee/reflexion-openai-parallel-calling-agent\", \n",
    "                        schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "                        evaluator=CustomQAEvaluator(llm=QuickAzureChatOpenAI(version='1106')),\n",
    "                        action_word = 'Tool invocations in parallel',\n",
    "                        observation_word = 'Tool-invocations results in parallel',\n",
    "                        use_chat_completion_api = True,\n",
    "                        azure_apenai_client = AsyncQuickAzureOpenAIClient(GPT_VER),\n",
    "                        file_logging=True,\n",
    "                        horizon = 3)\n",
    "\n",
    "\n",
    "openai_parallel_reflexion_agent.clear_logs()\n",
    "await openai_parallel_reflexion_agent._run_agent_trials_async(num_trials=2, \n",
    "query=\"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\",\n",
    "reference=\"The former former president of Korea is older. The sum of their age is 99.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('llm_agents')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3fb45ff54312d810d3b33eec9af47862c42661f076ce6b0d7045a13e18ceae3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
