{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Envs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, QuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "from configs.hd22_config import HD22Configuration\n",
    "config = HD22Configuration()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Query: Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\n",
      "[INFO] Trial 1\n",
      "[INFO] Thought 1: I need to find out who the former president of Korea is and who the MLB American League MVP of the last season is. Then, I need to find out their ages. I'll start by finding out who the former president of Korea is.\n",
      "[INFO] Action 1: YDCSearch(query='former president of Korea')\n",
      "[INFO] Observation 1: The most recent former president of South Korea is Moon Jae-In, who served from 2017 to 2022.\n",
      "[INFO] Thought 2: Now I know that the former president of Korea is Moon Jae-In. Next, I need to find out his age.\n",
      "[INFO] Action 2: YDCSearch(query='Moon Jae-In age')\n",
      "[INFO] Observation 2: Moon Jae-in was born on January 24, 1953.\n",
      "[INFO] Thought 3: Now I know that Moon Jae-In was born on January 24, 1953. I can calculate his age using the current year. But before that, I need to find out who the MLB American League MVP of the last season is.\n",
      "[INFO] Action 3: YDCSearch(query='MLB American League MVP 2021')\n",
      "[INFO] Observation 3: The American League MVP for 2021 was Shohei Ohtani from the Los Angeles Angels.\n",
      "[INFO] Thought 4: Now I know that the MLB American League MVP of the last season is Shohei Ohtani. Next, I need to find out his age.\n",
      "[INFO] Action 4: YDCSearch(query='Shohei Ohtani age')\n",
      "[INFO] Observation 4: Shohei Ohtani is 29 years old.\n",
      "[INFO] Thought 5: Now I know that Shohei Ohtani is 29 years old. I can calculate the sum of the ages of Moon Jae-In and Shohei Ohtani. But first, I need to calculate Moon Jae-In's age using his birth year and the current year.\n",
      "[INFO] Action 5: GetDatetime(IANA_timezone='Asia/Seoul')\n",
      "[INFO] Observation 5: timezone: Asia/Seoul, current time(year-month-day-hour-minute): 2023-12-4-16-31\n",
      "[INFO] Jugdement: You failed to provide an answer because you exceeded the permitted number of reasoning steps. You must give an answer within 5 steps.\n",
      "[INFO] Trial 2\n",
      "[INFO] Thought 1: I need to find out who the former president of Korea is and who the MLB American League MVP of the last season is. I'll start with the former president of Korea.\n",
      "[INFO] Action 1: YDCSearch(query='former president of Korea')\n",
      "[INFO] Observation 1: The most recent former president of South Korea is Moon Jae-in, who served as the 12th president from 10 May 2017 to 9 May 2022.\n",
      "[INFO] Thought 2: Now I need to find out Moon Jae-in's birth date to calculate his age.\n",
      "[INFO] Action 2: YDCSearch(query='Moon Jae-in birth date')\n",
      "[INFO] Observation 2: Moon Jae-in was born on January 24, 1953.\n",
      "[INFO] Thought 3: Now I need to find out who the MLB American League MVP of the last season is.\n",
      "[INFO] Action 3: YDCSearch(query='MLB American League MVP last season')\n",
      "[INFO] Observation 3: The Most Valuable Player (MVP) in the American League for the 2023 season was Shohei Ohtani from the Los Angeles Angels.\n",
      "[INFO] Thought 4: Now I need to find out Shohei Ohtani's birth date to calculate his age.\n",
      "[INFO] Action 4: YDCSearch(query='Shohei Ohtani birth date')\n",
      "[INFO] Observation 4: Shohei Ohtani was born on July 5, 1994.\n",
      "[INFO] Thought 5: Now I have the birth dates of both individuals. I can calculate their ages using Python. I'll start with Moon Jae-in.\n",
      "[INFO] Action 5: PythonREPL(command='from datetime import datetime\n",
      "moon_birthdate = datetime.strptime('1953-01-24', '%Y-%m-%d')\n",
      "moon_age = (datetime.now() - moon_birthdate).days // 365\n",
      "print(moon_age)')\n",
      "Python REPL can execute arbitrary code. Use with caution.\n",
      "[INFO] Observation 5: 70\n",
      "[INFO] Jugdement: You failed to provide an answer because you exceeded the permitted number of reasoning steps. You must give an answer within 5 steps.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, QuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "from configs.hd22_config import HD22Configuration\n",
    "config = HD22Configuration()\n",
    "\n",
    "#### ReAct Agent\n",
    "from agents.react.react_agent import ReActAgent\n",
    "\n",
    "GPT_VER = '0613'\n",
    "react_agent = ReActAgent(reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER), \n",
    "                        base_prompt=\"hwchase17/react-multi-input-json\", \n",
    "                        schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER), \n",
    "                        evaluator=CustomQAEvaluator(llm=QuickAzureChatOpenAI(version='1106')), \n",
    "                        stop_words=[\"Observation\"], \n",
    "                        thought_word= 'Thought', \n",
    "                        action_word='Action',\n",
    "                        file_logging=True,\n",
    "                        horizon=5)\n",
    "\n",
    "query = \"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\"\n",
    "reference = \"The former former president of Korea is older. The sum of their age is 99.\"\n",
    "num_trials = 2\n",
    "\n",
    "react_agent.clear_logs()\n",
    "# answer = react_agent.runnable_agent_step.invoke(query)\n",
    "# answer = react_agent.runnable_agent_episode.invoke(query, **{'reference':reference})\n",
    "answer = react_agent.runnable_agent_trial.invoke(query, **{'num_trials':num_trials, 'reference':reference})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflexion ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Query: Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\n",
      "[INFO] Trial 1\n",
      "[INFO] Thought 1: I need to find out who the former president of Korea is and who the MLB American League MVP of the last season is. Then, I need to find out their ages. I'll start by finding out who the former president of Korea is.\n",
      "[INFO] Action 1: YDCSearch(query='former president of Korea')\n",
      "[INFO] Observation 1: The most recent former president of South Korea is Moon Jae-In, who served from 2017 to 2022.\n",
      "[INFO] Thought 2: Now that I know the former president of Korea is Moon Jae-In, I need to find out his age.\n",
      "[INFO] Action 2: YDCSearch(query='Moon Jae-In age')\n",
      "[INFO] Observation 2: Moon Jae-in was born on January 24, 1953.\n",
      "[INFO] Thought 3: Now that I know Moon Jae-In was born on January 24, 1953, I can calculate his age. I'll use the current year to do this.\n",
      "[INFO] Action 3: GetDatetime(IANA_timezone='Asia/Seoul')\n",
      "[INFO] Observation 3: timezone: Asia/Seoul, current time(year-month-day-hour-minute): 2023-12-4-16-32\n",
      "[INFO] Thought 4: Now that I know the current year is 2023 in Korea, I can calculate Moon Jae-In's age by subtracting his birth year from the current year.\n",
      "[INFO] Action 4: PythonREPL(command='print(2023 - 1953)')\n",
      "[INFO] Observation 4: 70\n",
      "[INFO] Thought 5: Moon Jae-In is 70 years old. Now I need to find out who the MLB American League MVP of the last season is.\n",
      "[INFO] Action 5: YDCSearch(query='MLB American League MVP 2023')\n",
      "[INFO] Observation 5: The 2023 American League Most Valuable Player (MVP) was Shohei Ohtani from the Los Angeles Angels.\n",
      "[INFO] Jugdement: You failed to provide an answer because you exceeded the permitted number of reasoning steps. You must give an answer within 5 steps.\n",
      "[INFO] Trial 2\n",
      "[INFO] Reflexion......\n",
      "[INFO] You have attempted to answer following question before and failed. The following reflection(s) give a plan to avoid failing to answer the question in the same way you did previously. Use them to improve your strategy of correctly answering the given question.\n",
      "- In this trial, I failed to provide an answer within the allocated reasoning steps because I used separate steps to identify the individuals, calculate their ages, and then compare them. To mitigate this, I should streamline my process. For example, after identifying the individuals in question, I can directly search for their ages instead of their birth dates. This would save a step and allow me to provide an answer within the allocated steps. Additionally, I can perform the age comparison and summation in a single step using the PythonREPL tool, further optimizing the process.\n",
      "[INFO] Thought 1: I need to find out who the former president of Korea is and who the MLB American League MVP of the last season is. I'll start with the former president of Korea.\n",
      "[INFO] Action 1: YDCSearch(query='former president of Korea')\n",
      "[INFO] Observation 1: The most recent former president of South Korea is Moon Jae-In, who served from 2017 to 2022.\n",
      "[INFO] Thought 2: Now I need to find out Moon Jae-In's age.\n",
      "[INFO] Action 2: YDCSearch(query='Moon Jae-In age')\n",
      "[INFO] Observation 2: Moon Jae-in was born on January 24, 1953.\n",
      "[INFO] Thought 3: I need to calculate Moon Jae-In's age based on his birth year. I'll use the current year to do this.\n",
      "[INFO] Action 3: GetDatetime(IANA_timezone='Asia/Seoul')\n",
      "[INFO] Observation 3: timezone: Asia/Seoul, current time(year-month-day-hour-minute): 2023-12-4-16-33\n",
      "[INFO] Thought 4: Now I know the current year is 2023. I can calculate Moon Jae-In's age by subtracting his birth year from the current year.\n",
      "[INFO] Action 4: PythonREPL(command='print(2023 - 1953)')\n",
      "[INFO] Observation 4: 70\n",
      "[INFO] Thought 5: Moon Jae-In is 70 years old. Now I need to find out who the MLB American League MVP of the last season is.\n",
      "[INFO] Action 5: YDCSearch(query='MLB American League MVP 2023')\n",
      "[INFO] Observation 5: The 2023 American League Most Valuable Player (MVP) was Shohei Ohtani from the Los Angeles Angels.\n",
      "[INFO] Jugdement: You failed to provide an answer because you exceeded the permitted number of reasoning steps. You must give an answer within 5 steps.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, QuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "from configs.hd22_config import HD22Configuration\n",
    "config = HD22Configuration()\n",
    "\n",
    "#### Reflexion Agent\n",
    "from agents.react.react_agent_with_reflexion import ReActWithReflexionAgent\n",
    "from agents.react.react_fewshot_examples import REACT_REFLECTION_HEADER, REACT_REFLECTIONS\n",
    "from chains.reflexion_chains import BaseReflexionChain\n",
    "\n",
    "GPT_VER = '0613'   \n",
    "reflexion_chains = BaseReflexionChain(\n",
    "                    reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER),\n",
    "                    prompt=\"jet-taekyo-lee/experimental-reflextion\", \n",
    "                    schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "                    reflexion_examples=REACT_REFLECTIONS\n",
    "                    )\n",
    "\n",
    "reflexion_prompt = \"jet-taekyo-lee/reflexion-react\"\n",
    "reflexion_agent = ReActWithReflexionAgent(\n",
    "                        reflexion_chain = reflexion_chains,\n",
    "                        reflexion_header = REACT_REFLECTION_HEADER,\n",
    "                        reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER), \n",
    "                        base_prompt=\"hwchase17/react-multi-input-json\", \n",
    "                        schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER), \n",
    "                        evaluator=CustomQAEvaluator(llm=QuickAzureChatOpenAI(version='1106')), \n",
    "                        stop_words=[\"Observation\"], \n",
    "                        thought_word= 'Thought', \n",
    "                        action_word='Action',\n",
    "                        file_logging=True,\n",
    "                        horizon=5)\n",
    "\n",
    "\n",
    "query = \"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\"\n",
    "reference = \"The former former president of Korea is older. The sum of their age is 99.\"\n",
    "num_trials = 2\n",
    "\n",
    "reflexion_agent.clear_logs()\n",
    "# answer = reflexion_agent.runnable_agent_step.invoke(query)\n",
    "# answer = reflexion_agent.runnable_agent_episode.invoke(query, **{'reference':reference})\n",
    "answer = reflexion_agent.runnable_agent_trial.invoke(query, **{'num_trials':num_trials, 'reference':reference})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Regacy agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Query: Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\n",
      "[INFO] Trial 1\n",
      "[INFO] Invoking 1: YDCSearch(query='former president of Korea age')\n",
      "[INFO] Observation 1: The context provided does not specify which former president of South Korea's age is being asked for. There have been multiple former presidents of South Korea. Please provide more specific information.\n",
      "[INFO] Invoking 2: Could you please specify which former president of Korea you are referring to? There have been multiple former presidents.\n",
      "[INFO] Answer: Could you please specify which former president of Korea you are referring to? There have been multiple former presidents.\n",
      "[INFO] Jugdement: Your answer is incorrect. The correct answer is \"The former former president of Korea is older. The sum of their age is 99.\"\n",
      "[INFO] Trial 2\n",
      "[INFO] Invoking 1: YDCSearch(query='former president of Korea age')\n",
      "[INFO] Observation 1: The context provided does not specify which former president of South Korea's age is being asked for. There have been multiple former presidents of South Korea. Please provide more specific information.\n",
      "[INFO] Invoking 2: Could you please specify which former president of Korea you are referring to? There have been multiple former presidents.\n",
      "[INFO] Answer: Could you please specify which former president of Korea you are referring to? There have been multiple former presidents.\n",
      "[INFO] Jugdement: Your answer is incorrect. The correct answer is \"The former former president of Korea is older. The sum of their age is 99.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, QuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "from configs.hd22_config import HD22Configuration\n",
    "config = HD22Configuration()\n",
    "\n",
    "# #### OepnAI Agent\n",
    "GPT_VER = '0613' \n",
    "from agents.openai_legacy.openai_legacy_agent import OpenAILegacyAgent\n",
    "openai_agent = OpenAILegacyAgent(\n",
    "    reasoninig_engine = QuickAzureChatOpenAI(version=GPT_VER),\n",
    "    base_prompt = \"jet-taekyo-lee/openai-function-calling-agent\",\n",
    "    schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "    evaluator = CustomQAEvaluator(llm=QuickAzureChatOpenAI(version='1106')),\n",
    "    action_word = 'Invoking',\n",
    "    horizon = 5)\n",
    "\n",
    "\n",
    "query = \"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\"\n",
    "reference = \"The former former president of Korea is older. The sum of their age is 99.\"\n",
    "num_trials = 2\n",
    "\n",
    "openai_agent.clear_logs()\n",
    "# answer = openai_agent.runnable_agent_step.invoke(query)\n",
    "# answer = openai_agent.runnable_agent_episode.invoke(query, **{'reference':reference})\n",
    "answer = openai_agent.runnable_agent_trial.invoke(query, **{'num_trials':num_trials, 'reference':reference})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflexion OpenAI Legacy agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Query: Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\n",
      "[INFO] Trial 1\n",
      "[INFO] Invoking 1: YDCSearch(query='former president of Korea age')\n",
      "[INFO] Observation 1: The context provided does not specify which former president of South Korea's age you are asking about. There have been multiple former presidents of South Korea. Please provide more specific information.\n",
      "[INFO] Invoking 2: Could you please specify which former president of Korea you are referring to? There have been multiple former presidents of Korea.\n",
      "[INFO] Answer: Could you please specify which former president of Korea you are referring to? There have been multiple former presidents of Korea.\n",
      "[INFO] Jugdement: Your answer is incorrect. The correct answer is \"The former former president of Korea is older. The sum of their age is 99.\"\n",
      "[INFO] Trial 2\n",
      "[INFO] Reflexion......\n",
      "[INFO] You have attempted to answer following question before and failed. The following reflection(s) give a plan to avoid failing to answer the question in the same way you did previously. Use them to improve your strategy of correctly answering the given question.\n",
      "- In this trial, the query was ambiguous as it did not specify which former president of Korea's age was being asked for. This led to an incorrect answer as I was unable to determine the correct individual to search for. In the future, I should ask for clarification when the query is ambiguous or lacks specific information. Additionally, I did not attempt to find the age of the MLB American League MVP of the last season, which was also part of the query. A better approach would be to first ask for clarification on the former president of Korea, and then proceed to find the age of the MLB American League MVP of the last season.\n",
      "[INFO] Invoking 1: I'm sorry for the confusion, but could you please specify which former president of Korea you are referring to? There have been several former presidents in Korea.\n",
      "[INFO] Answer: I'm sorry for the confusion, but could you please specify which former president of Korea you are referring to? There have been several former presidents in Korea.\n",
      "[INFO] Jugdement: Your answer is incorrect. The correct answer is \"The former former president of Korea is older. The sum of their age is 99.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, QuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "from configs.hd22_config import HD22Configuration\n",
    "config = HD22Configuration()\n",
    "\n",
    "# # #### Reflexion OepnAI Agent\n",
    "from agents.openai_legacy.openai_legacy_with_reflexion_agent import OpenAILegacyWithReflexionAgent\n",
    "from agents.openai_legacy.openai_legacy_fewshot_examples import OPENAI_LEGACY_REFLECTIONS, OPENAI_LEGACY_REFLECTION_HEADER\n",
    "from chains.reflexion_chains import BaseReflexionChain\n",
    "\n",
    "\n",
    "GPT_VER = '0613'    \n",
    "openai_legacy_reflexion_chains = BaseReflexionChain(\n",
    "                    reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER),\n",
    "                    prompt=\"jet-taekyo-lee/openai-reflexion-chain-prompt\", \n",
    "                    schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "                    reflexion_examples=OPENAI_LEGACY_REFLECTIONS\n",
    "                    )\n",
    "\n",
    "\n",
    "openai_legacy_reflexion_agent = OpenAILegacyWithReflexionAgent(\n",
    "                        reflexion_chain = openai_legacy_reflexion_chains,\n",
    "                        reflexion_header = OPENAI_LEGACY_REFLECTION_HEADER,\n",
    "                        reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER), \n",
    "                        base_prompt=\"jet-taekyo-lee/rexlexion-openai-function-calling-agent\", \n",
    "                        schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "                        evaluator=CustomQAEvaluator(llm=QuickAzureChatOpenAI(version='1106')),\n",
    "                        action_word='Invoking',\n",
    "                        file_logging=True,\n",
    "                        horizon = 5)\n",
    "\n",
    "\n",
    "query = \"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\"\n",
    "reference = \"The former former president of Korea is older. The sum of their age is 99.\"\n",
    "num_trials = 2\n",
    "\n",
    "openai_legacy_reflexion_agent.clear_logs()\n",
    "# answer = openai_legacy_reflexion_agent.runnable_agent_step.invoke(query)\n",
    "# answer = openai_legacy_reflexion_agent.runnable_agent_episode.invoke(query, **{'reference':reference})\n",
    "answer = openai_legacy_reflexion_agent.runnable_agent_trial.invoke(query, **{'num_trials':num_trials, 'reference':reference})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Function Calling agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Query: Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\n",
      "[INFO] Trial 1\n",
      "[INFO] (step 1-action) Tool invocations in parallel: [Tool 1-> YDCSearch(query=former president of Korea age), Tool 2-> YDCSearch(query=last season MLB American League MVP age)]\n",
      "[INFO] (step 1-observation) :: [Tool 1-> The age of a former president of South Korea would depend on which former president you are referring to. As of my knowledge cutoff in 2023, here are the ages of the living former presidents:\n",
      "\n",
      "1. Lee Myung-bak (이명박) - Born December 19, 1941, so he would be 81 years old.\n",
      "2. Park Geun-hye (박근혜) - Born February 2, 1952, so she would be 71 years old.\n",
      "\n",
      "Please note that these ages are based on the birthdates provided and the current year being 2023. If you are asking about a specific former president, please provide their name for a more accurate response., Tool 2-> The American League MVP for the 2023 MLB season was Shohei Ohtani. As of my knowledge cutoff in 2023, Shohei Ohtani was born on July 5, 1994. Therefore, during the 2023 MLB season, he would have turned 29 years old.]\n",
      "[INFO] (step 2-action) Tool invocations in parallel: Now I can answer directly without resorting to any tool.\n",
      "[INFO] Answer: Please provide the name of the specific former president of South Korea you're referring to for me to give an accurate comparison and sum of ages.\n",
      "[INFO] Jugdement: Your answer is incorrect. The correct answer is \"The former former president of Korea is older. The sum of their age is 99.\"\n",
      "[INFO] Trial 2\n",
      "[INFO] (step 1-action) Tool invocations in parallel: [Tool 1-> YDCSearch(query=former president of South Korea), Tool 2-> YDCSearch(query=MLB American League MVP last season)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RateLimitError for get_function_observation. -----> Will automatically retry 20 seconds later.\n",
      "20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 RateLimitError for get_function_observation. -----> Will automatically retry 20 seconds later.\n",
      "20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] (step 1-observation) :: [Tool 1-> The former president of South Korea is Park Geun-hye. She served as the 11th president of South Korea from 2013 until her impeachment in 2017. Park was the first woman to be elected as president of South Korea and the first female president popularly elected as head of state in East Asia. Her presidency ended when she was impeached and subsequently convicted on charges related to corruption. Park Geun-hye was pardoned in December 2021 by then-President Moon Jae-in., Tool 2-> The American League MVP for the last season (2022) was Aaron Judge of the New York Yankees.]\n",
      "[INFO] (step 2-action) Tool invocations in parallel: [Tool 1-> YDCSearch(query=Park Geun-hye birthdate), Tool 2-> YDCSearch(query=Aaron Judge birthdate)]\n",
      "[INFO] (step 2-observation) :: [Tool 1-> Park Geun-hye was born on February 2, 1952., Tool 2-> Aaron Judge's birthday is on April 26.]\n",
      "[INFO] (step 3-action) Tool invocations in parallel: [Tool 1-> PythonREPL(command=print(2023 - 1952, 2023 - 1992, (2023 - 1952) + (2023 - 1992)))]\n",
      "Python REPL can execute arbitrary code. Use with caution.\n",
      "[INFO] (step 3-observation) :: [Tool 1-> 71 31 102]\n",
      "[INFO] (step 4-action) Tool invocations in parallel: Now I can answer directly without resorting to any tool.\n",
      "[INFO] Answer: Park Geun-hye is older. The sum of their ages is 102 years.\n",
      "[INFO] Jugdement: Your answer is incorrect. The correct answer is \"The former former president of Korea is older. The sum of their age is 99.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, AsyncQuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "from configs.hd22_config import HD22Configuration\n",
    "import asyncio\n",
    "config = HD22Configuration()\n",
    "\n",
    "#### Parallel Function Calling Agent\n",
    "GPT_VER = '1106' \n",
    "from agents.openai_parallel.openai_parallel_agent import OpenAIParallelAgent\n",
    "\n",
    "openai_parallel_agent = OpenAIParallelAgent(\n",
    "    reasoninig_engine = QuickAzureChatOpenAI(version=GPT_VER),\n",
    "    base_prompt = 'jet-taekyo-lee/parallel-function-calling-agent',\n",
    "    schemas_and_tools = DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "    evaluator = CustomQAEvaluator(llm=QuickAzureChatOpenAI('0613')),\n",
    "    action_word = 'Tool invocations in parallel',\n",
    "    observation_word = 'Tool-invocations results in parallel',\n",
    "    use_chat_completion_api = True,\n",
    "    azure_apenai_client = AsyncQuickAzureOpenAIClient(GPT_VER),\n",
    "    horizon = 5\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "query = \"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\"\n",
    "reference = \"The former former president of Korea is older. The sum of their age is 99.\"\n",
    "num_trials = 2\n",
    "\n",
    "\n",
    "openai_parallel_agent.clear_logs()\n",
    "\n",
    "# await openai_parallel_agent.runnable_agent_step.ainvoke(query)\n",
    "# await openai_parallel_agent.runnable_agent_episode.ainvoke(query, **{'reference':reference})\n",
    "await openai_parallel_agent.runnable_agent_trial.ainvoke(query, **{'reference':reference, 'num_trials':num_trials})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflexion + Parallel Function Calling agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Query: Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\n",
      "[INFO] Trial 1\n",
      "[INFO] (step 1-action) Tool invocations in parallel: [Tool 1-> YDCSearch(query=former president of South Korea), Tool 2-> YDCSearch(query=MLB American League MVP last season)]\n",
      "[INFO] (step 1-observation) :: [Tool 1-> Park Geun-hye is a former president of South Korea who served from 2013 until her impeachment in 2017. She was the country's first female president and the first president to be born after the founding of South Korea. Her presidency ended when she was impeached and removed from office due to a corruption scandal involving her close confidante, Choi Soon-sil. Park was subsequently convicted on related charges and sentenced to prison. She was pardoned and released from prison in December 2021., Tool 2-> The American League MVP for the last season (2023) was Shohei Ohtani of the LA Angels.]\n",
      "[INFO] (step 2-action) Tool invocations in parallel: [Tool 1-> YDCSearch(query=Park Geun-hye birthdate), Tool 2-> YDCSearch(query=Shohei Ohtani birthdate)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RateLimitError for get_function_observation. -----> Will automatically retry 20 seconds later.\n",
      "20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 RateLimitError for get_function_observation. -----> Will automatically retry 20 seconds later.\n",
      "20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 RateLimitError for get_function_observation. -----> Will automatically retry 20 seconds later.\n",
      "20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] (step 2-observation) :: [Tool 1-> Park Geun-hye was born on February 2, 1952., Tool 2-> Shohei Ohtani was born on July 5, 1994.]\n",
      "[INFO] (step 3-action) Tool invocations in parallel: [Tool 1-> PythonREPL(command=print(2023 - 1952 + 2023 - 1994))]\n",
      "[INFO] (step 3-observation) :: [Tool 1-> 100]\n",
      "[INFO] (step 4-action) Tool invocations in parallel: Now I can answer directly without resorting to any tool.\n",
      "[INFO] Answer: Park Geun-hye is older than Shohei Ohtani. If you sum up their ages, the result is 100.\n",
      "[INFO] Jugdement: Your answer is incorrect. The correct answer is \"The former former president of Korea is older. The sum of their age is 99.\"\n",
      "[INFO] Trial 2\n",
      "[INFO] Reflexion......\n",
      "[INFO] You have attempted to answer following question before and failed. The following reflection(s) give a plan to avoid failing to answer the question in the same way you did previously. Use them to improve your strategy of correctly answering the given question.\n",
      "- Reflection: The error in the previous trial occurred because the calculation of the ages was based on the current year (2023) without considering the actual birthdates and whether the individuals had already had their birthdays for the year. This led to an incorrect sum of their ages. The correct approach would be to calculate each person's age by considering if their birthday has passed in the current year and then summing those ages.\n",
      "\n",
      "To prevent this error in future attempts, the strategy should be as follows:\n",
      "\n",
      "1. Determine the current date to establish whether each individual has had their birthday for the current year.\n",
      "2. Calculate the age of each individual by subtracting their birth year from the current year. If their birthday has not yet occurred in the current year, subtract an additional year to get the correct age.\n",
      "3. Sum the ages of the two individuals to get the final result.\n",
      "\n",
      "This approach ensures that the calculation of ages is accurate and accounts for whether or not the individuals have celebrated their birthdays in the current year.\n",
      "[INFO] (step 1-action) Tool invocations in parallel: [Tool 1-> YDCSearch(query=former president of Korea), Tool 2-> YDCSearch(query=MLB American League MVP last season)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RateLimitError for get_function_observation. -----> Will automatically retry 20 seconds later.\n",
      "20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 RateLimitError for get_function_observation. -----> Will automatically retry 20 seconds later.\n",
      "20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] (step 1-observation) :: [Tool 1-> Former President Park Geun-hye of South Korea served as the 11th president from 2013 until her impeachment in 2017. She was the first woman to be elected as president in South Korea and the first female president popularly elected as head of state in East Asia. Park was impeached and removed from office on charges of corruption and abuse of power, and she was subsequently convicted and imprisoned. However, she was pardoned by her successor, President Moon Jae-in, in December 2021, citing her deteriorating health and the need to promote national unity. Park was released from prison and returned home in March 2022., Tool 2-> The American League MVP for the last season (2023) was Shohei Ohtani of the LA Angels.]\n",
      "[INFO] (step 2-action) Tool invocations in parallel: [Tool 1-> GetDatetime(IANA_timezone=Asia/Seoul), Tool 2-> YDCSearch(query=Park Geun-hye date of birth), Tool 3-> YDCSearch(query=Shohei Ohtani date of birth)]\n",
      "[INFO] (step 2-observation) :: [Tool 1-> timezone: Asia/Seoul, current time(year-month-day-hour-minute): 2023-12-4-16-42, Tool 2-> Park Geun-hye was born on February 2, 1952., Tool 3-> Shohei Ohtani was born on July 5, 1994.]\n",
      "[INFO] (step 3-action) Tool invocations in parallel: [Tool 1-> PythonREPL(command=print(2023 - 1952 - (1 if (12, 4) < (2, 2) else 0) + 2023 - 1994 - (1 if (12, 4) < (7, 5) else 0)))]\n",
      "[INFO] (step 3-observation) :: [Tool 1-> 100]\n",
      "[INFO] (step 4-action) Tool invocations in parallel: Now I can answer directly without resorting to any tool.\n",
      "[INFO] Answer: Park Geun-hye, the former president of Korea, is older than Shohei Ohtani, the MLB American League MVP of the last season. When you sum up their ages, the result is 100 years.\n",
      "[INFO] Jugdement: Your answer is incorrect. The correct answer is \"The former former president of Korea is older. The sum of their age is 99.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from reasoning_engines.langchain_llm_wrappers import QuickAzureChatOpenAI, AsyncQuickAzureOpenAIClient\n",
    "from tools.get_tools import DefaultSchemasTools\n",
    "from langchain import hub\n",
    "from utils.load_envs import Environ\n",
    "from chains.qa_evaluators import CustomQAEvaluator\n",
    "import asyncio\n",
    "config = HD22Configuration()\n",
    "\n",
    "#### Reflexion + Parallel Function Calling Agent\n",
    "from chains.reflexion_chains import BaseReflexionChain\n",
    "from agents.openai_parallel.openai_parallel_with_reflexion_agent import OpenAIParallelWithReflexionAgent\n",
    "from agents.openai_parallel.openai_parallel_fewshot_examples import OPENAI_PARALLEL_REFLECTIONS, OPENAI_PARALLEL_REFLECTION_HEADER\n",
    "\n",
    "GPT_VER = '1106'    \n",
    "openai_parallel_reflexion_chains = BaseReflexionChain(\n",
    "                    reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER),\n",
    "                    prompt=\"jet-taekyo-lee/openai-parallel-calling-reflexion-chain-prompt\", \n",
    "                    schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "                    reflexion_examples=OPENAI_PARALLEL_REFLECTIONS\n",
    "                    )\n",
    "\n",
    "\n",
    "openai_parallel_reflexion_agent = OpenAIParallelWithReflexionAgent(\n",
    "                        reflexion_chain = openai_parallel_reflexion_chains,\n",
    "                        reflexion_header = OPENAI_PARALLEL_REFLECTION_HEADER,\n",
    "                        reasoninig_engine=QuickAzureChatOpenAI(version=GPT_VER), \n",
    "                        base_prompt=\"jet-taekyo-lee/reflexion-openai-parallel-calling-agent\", \n",
    "                        schemas_and_tools=DefaultSchemasTools(azure_gpt_version=GPT_VER),\n",
    "                        evaluator=CustomQAEvaluator(llm=QuickAzureChatOpenAI(version='1106')),\n",
    "                        action_word = 'Tool invocations in parallel',\n",
    "                        observation_word = 'Tool-invocations results in parallel',\n",
    "                        use_chat_completion_api = True,\n",
    "                        azure_apenai_client = AsyncQuickAzureOpenAIClient(GPT_VER),\n",
    "                        file_logging=True,\n",
    "                        horizon = 5)\n",
    "\n",
    "query = \"Who is older? The former president of Korea vs. the MLB American League MVP of the last season. What is the result if you sum up the ages of the two?\"\n",
    "reference = \"The former former president of Korea is older. The sum of their age is 99.\"\n",
    "num_trials = 2\n",
    "\n",
    "\n",
    "openai_parallel_reflexion_agent.clear_logs()\n",
    "# await openai_parallel_reflexion_agent.runnable_agent_step.ainvoke(query)\n",
    "# await openai_parallel_reflexion_agent.runnable_agent_episode.ainvoke(query, **{'reference':reference})\n",
    "await openai_parallel_reflexion_agent.runnable_agent_trial.ainvoke(query, **{'reference':reference, 'num_trials':num_trials})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('llm_agents')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3fb45ff54312d810d3b33eec9af47862c42661f076ce6b0d7045a13e18ceae3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
